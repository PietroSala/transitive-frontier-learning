{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad351101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from LogicLanguage.ipynb\n",
      "importing Jupyter notebook from BoolRepres.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log2 \n",
    "\n",
    "import import_ipynb\n",
    "from LogicLanguage import LogicLanguage\n",
    "from BoolRepres import BoolRepres\n",
    "\n",
    "class ConstraintDefiner():\n",
    "    \n",
    "    def __init__(self, nameVars, maxValues): \n",
    "        # Init: vars + logicClass  # priorityList -> [(var1, var2),(var2,var4),...]=> var1 ha priorità su var2 nel SAT ecc.\n",
    "        self.constr   = [] \n",
    "        self.dfVars   = self.__init_dfVars(nameVars, maxValues)\n",
    "        self.df_default = None\n",
    "        \n",
    "        self.edgeList = [] # list of edges. es: [(a,b), (c,b), (b,k), ...]# Assume No cilci: [(a,b), (b,a)] NO!!!\n",
    "        self.oper = self.__init_operators(None)\n",
    "        self.mll  = LogicLanguage()  \n",
    "\n",
    "        \n",
    "    def __init_operators(self, oper):\n",
    "        if oper is None:\n",
    "            oper = {\"AND\":'and', 'OR':'or', 'NOT':'not', 'TRUE':'true', 'FALSE':'false'} \n",
    "            #print('Will use the following operator as default:')\n",
    "            #print( ''.join([f'{k} as {v}, ' for k,v in oper.items()])[:-1]) \n",
    "            return oper\n",
    "        return oper\n",
    "\n",
    "    #=============================================================================\n",
    "    # ------------------------- INITIALIZATION VARIABLES -------------------------\n",
    "    \n",
    "    def __init_dfVars(self, nameVars, maxValues):\n",
    "        # Rappresentazione in bit\n",
    "        dfVars = (pd.DataFrame({'V':nameVars, 'maxV':maxValues})\n",
    "                      .assign(nbit=lambda x: [ 1 if mV==0 else int(log2(mV))+1 for mV in x.maxV])\n",
    "                      .set_index('V'))\n",
    "        for col in ['XL','XU','YL','YU']:\n",
    "            dfVars[col] = dfVars.apply(lambda v: BoolRepres(v.name+'_'+col, v['nbit']) , axis=1)\n",
    "        return dfVars\n",
    "    \n",
    "    def get_varsName(self):\n",
    "        return self.dfVars[['XL','XU','YL','YU']].applymap(lambda br: br.bitsName).sum().sum()\n",
    "\n",
    "    #=============================================================================\n",
    "    # -------------------------- SET USER OPTIONS SETTING ------------------------\n",
    "    def set_saveSpace(self, saveSpace=False):\n",
    "        self.mll.set_saveSpace(saveSpace)\n",
    "        \n",
    "    def set_seed(self, seed):\n",
    "        self.mll.set_seed(seed)\n",
    "        \n",
    "    def set_resetTree(self, resetTree):\n",
    "        self.mll.set_resetTree(resetTree)\n",
    "        \n",
    "    def set_childrenChoice(self, _type='random'):\n",
    "        # default -> 'random'\n",
    "        # 'min_avgLenPath' or 'min_power': \n",
    "        self.mll.set_childrenChoice(_type=_type)\n",
    "    \n",
    "    def set_saturate_freeVars(self, saturate=None): # self, defaultVars, groups=None \n",
    "        \n",
    "        if saturate is None:\n",
    "            self.mll.set_groups(None)\n",
    "            self.mll.set_default(None)\n",
    "            self.mll.set_saturate_options(False)\n",
    "            return\n",
    "               \n",
    "        if saturate not in ['all','effective']:\n",
    "            print('Wrong paramiter insered')\n",
    "            return \n",
    "        \n",
    "        # if here, for sure saturate = 'all'\n",
    "        # Create default dictionary\n",
    "        # Assumo default-> Lower bound = 0, Upper bound = max\n",
    "        def_list, defaultVal, groups = [], {}, None\n",
    "        def_list += self.dfVars['XL'].apply(lambda br: br.set_to(0).to_dict()).tolist()\n",
    "        def_list += self.dfVars['YL'].apply(lambda br: br.set_to(0).to_dict()).tolist()\n",
    "        def_list += self.dfVars[['maxV','XU']].apply(lambda row: row['XU'].set_to(row['maxV']).to_dict(), axis=1).tolist()\n",
    "        def_list += self.dfVars[['maxV','YU']].apply(lambda row: row['YU'].set_to(row['maxV']).to_dict(), axis=1).tolist()\n",
    "        for d in def_list: \n",
    "            defaultVal |= d\n",
    "        \n",
    "        # Create atomsGroups, if required \n",
    "        if saturate == 'effective':\n",
    "            groups = self.dfVars[['XL','XU','YL','YU']].applymap(lambda br: br.get_bitsName()).values.reshape(len(self.dfVars)*4)\n",
    "        \n",
    "        # set LogicLanguage\n",
    "        self.mll.set_groups(groups)\n",
    "        self.mll.set_default(defaultVal)\n",
    "        self.mll.set_saturate_options(state = True, freeVars=saturate, values='default')\n",
    "        \n",
    "        #return defaultVal\n",
    "    \n",
    "    #-------------------------------------------------------------------------------\n",
    "    def set_priority(self, priorityList=[] , digitPrior='None'): \n",
    "        # priorityList -> list of edges. es: [(a,b), (c,b), (b,k), ...]# Assume No cilci: [(a,b), (b,a)] NO!!!\n",
    "        # priorityList -> work in progress\n",
    "        \n",
    "        if  digitPrior == 'None' : \n",
    "            self.edgeList = [] \n",
    "            \n",
    "        elif digitPrior == 'Simple': \n",
    "            # Ogni bit di una variabile var_XL/XU/YL/YU_k ha priorità sul relavito bit k-1\n",
    "            # es a_XL_3 ha priorità su a_XL_2,  a_XU_3 ha priorità su a_XU_2, ecc.\n",
    "            self.edgeList = self.dfVars[['XL','XU','YL','YU']].applymap(lambda br: [(br[i],br[i+1]) for i in range(br.nBits-1)]).sum().sum()\n",
    "            \n",
    "        elif digitPrior == 'Complete':\n",
    "            # Ogni variabile var_XL/XU/YL/YU_k ha priorità su tutti i bit k-1. \n",
    "            # es: a_XL_3 ha priorità su a_XL_2, a_XU_2, a_YL_2, a_YU_2\n",
    "            temp = [] \n",
    "            for (var, nBit) in self.dfVars['nbit'].reset_index().values:\n",
    "                for n in range(nBit):\n",
    "                    for iSide in ['XL','XU','YL','YU']:\n",
    "                        for jSide in ['XL','XU','YL','YU']:\n",
    "                            temp.append( (f\"{var}_{iSide}_{nBit-n}\", f\"{var}_{jSide}_{nBit-n-1}\") )\n",
    "            self.edgeList = temp\n",
    "        else: \n",
    "            print(f\"Paramiter {digitPrior} not finded\")\n",
    "            return None\n",
    "                  \n",
    "        # Define user priority\n",
    "        temp = [] \n",
    "        for v,u in priorityList:\n",
    "            for v_side in ['XL','XU','YL','YU']:\n",
    "                for u_side in ['XL','XU','YL','YU']:\n",
    "                    temp.append( (f\"{v}_{v_side}_0\", f\"{u}_{u_side}_{self.dfVars.at[u,'nbit']-1}\") )\n",
    "        self.edgeList += temp\n",
    "        \n",
    "        # update priority in LogicLanguage\n",
    "        self.mll.set_priority(self.edgeList)\n",
    "                    \n",
    "\n",
    "       \n",
    "    #============================================================================= \n",
    "    # --------------------------- SAT SOLVER ----------------------------\n",
    "    def reject_solut(self, solutSet):\n",
    "        sol=[]\n",
    "        for k,v in solutSet.items():\n",
    "            if   v == \"true\"  : sol.append(k)\n",
    "            elif v == \"false\" : sol.append(f'not {k}')\n",
    "            else: print(\"wrong paramiter: ignored. Only True or False \")\n",
    "        return f'not({\" and \".join(sol)})'\n",
    "         \n",
    "    #-------------------------------------------------------------------        \n",
    "    def addConstr(self, logicStr): \n",
    "        self.constr.append(f'({logicStr})')   \n",
    "        self.mll.add_constr(f'({logicStr})', reset_old=False)\n",
    "  \n",
    "    #-------------------------------------------------------------------  \n",
    "    def Sat_Solver(self, verbose=False, test=None):\n",
    "        return self.mll.sat_Solver(verbose=verbose, test=test)#, self.mll.all_varTree # ritorno treeVars x grafico albero delle variabili\n",
    "    \n",
    "    #=============================================================================\n",
    "    # --------------------------- INITIAL CONSTRAINTS ----------------------------\n",
    "    def save_Constr_txt(self, fileName='saved_Constraints'):\n",
    "        with open(fileName+'.txt', 'w') as f:\n",
    "            f.write('\\n'.join(self.constr)) \n",
    "    #-------------------------------------------------------------------            \n",
    "    def load_Constr_txt(self, fileName='saved_Constraints', returns=False):\n",
    "        with open(fileName+'.txt', 'r') as f:\n",
    "            self.constr = f.read().split('\\n')\n",
    "            if returns: return self.constr \n",
    "        \n",
    "    #------------------------------------------------------------------- \n",
    "    def init_constr(self):\n",
    "        formula, dfVars = [], self.dfVars  \n",
    "        #---------------------------------\n",
    "        # Constraints:  Phy_init_max --> Var_X/Y L/U <= maxVal \n",
    "        for col in ['XL','XU','YL','YU']:\n",
    "            formula += dfVars.apply(lambda x: x[col] <= x['maxV'], axis=1).tolist()\n",
    "            \n",
    "        #---------------------------------\n",
    "        # Constraints: Phy_init_interval --> Var_X L <= Var_X L  \n",
    "        formula += dfVars.apply(lambda x: x['XL'] <= x['XU'], axis=1).tolist()\n",
    "        formula += dfVars.apply(lambda x: x['YL'] <= x['YU'], axis=1).tolist()\n",
    "        \n",
    "        #---------------------------------\n",
    "        # Constraints: Phy_init_rule --> define the equivalent to \" a_X -> not a_y\" ==> \"not a_x or a_y\" in intervals \n",
    "        def init_rule(row, iL, iU, jL, jU):\n",
    "            v_x = f\"{row[iL] > 0} or {row[iU] < row['maxV']}\"\n",
    "            v_y = f\"{row[jL] == 0} and {(row[jU] == row['maxV'])}\"\n",
    "            return f'(not({v_x}) or ({v_y}))'\n",
    "        \n",
    "        formula += dfVars.apply(lambda row: init_rule(row,'XL','XU','YL','YU') , axis=1).tolist() \n",
    "        formula += dfVars.apply(lambda row: init_rule(row,'YL','YU','XL','XU') , axis=1).tolist() \n",
    "        \n",
    "        or_X = dfVars.apply(lambda row: f\"{row['XL']>0} or {row['XU']<row['maxV']}\" , axis=1).tolist()\n",
    "        or_Y = dfVars.apply(lambda row: f\"{row['YL']>0} or {row['YU']<row['maxV']}\" , axis=1).tolist()\n",
    "        return f\"({' and '.join(formula)}) and ({' or '.join(or_X)}) and ({' or '.join(or_Y)})\"\n",
    "    \n",
    "    #=============================================================================\n",
    "    # ------------------------------- DECODE RULE -------------------------------    \n",
    "    def decodeRule(self, res): #res = solutSet = {nomeVar_[X|Y]_[L|U]_nbit: true/false}\n",
    "        #------------------------\n",
    "        # Decode Bool:\n",
    "        def decode(varBits, res):\n",
    "            return int( ''.join(['1' if res[k]=='true' else '0' for k in varBits]), 2)  \n",
    "        df_res = self.dfVars[['XL','XU','YL','YU']].applymap(lambda br: decode(br.bits, res))\n",
    "        \n",
    "        #-----------------------\n",
    "        # Rule extraction\n",
    "        notX = (df_res.XL==0) & (df_res.XU==self.dfVars.maxV) # Da rimuovere da X\n",
    "        notY = (df_res.YL==0) & (df_res.YU==self.dfVars.maxV) # Da rimuovere da Y\n",
    "\n",
    "        #-----------------------\n",
    "        # type Output: only Dataset \n",
    "        df_X = df_res.loc[-notX,:][['XL','XU']].rename(columns={'XL':'L','XU':'U'}).astype(int)\n",
    "        df_Y = df_res.loc[-notY,:][['YL','YU']].rename(columns={'YL':'L','YU':'U'}).astype(int)\n",
    "        \n",
    "        # TEMP: Pretty Output -> String intervals \n",
    "        df_X_pretty = df_X.index+'['+ df_X.L.astype(str)+','+df_X.U.astype(str)+']'\n",
    "        df_Y_pretty = df_Y.index+'['+ df_Y.L.astype(str)+','+df_Y.U.astype(str)+']'\n",
    "        s = f\"{', '.join(df_X_pretty.tolist())} --> {', '.join(df_Y_pretty.tolist())}\"\n",
    "        \n",
    "        return df_X, df_Y, s # in form: {'df_X':df_X, 'df_Y':df_Y, 'str':s}\n",
    "        \n",
    "    \n",
    "    #=============================================================================\n",
    "    #----------------------------- COMMON FUNCTIONS ------------------------------\n",
    "    def __extend(self, var, sL, sU, L, U):\n",
    "        return f\"({var[sL] <= L} and {U <= var[sU]})\"\n",
    "    \n",
    "    def __reduce(self, var, sL, sU, L, U):\n",
    "        return f\"({L <= var[sL]} and {var[sU] <= U})\"\n",
    "    \n",
    "    def __notIn(self, var, side):\n",
    "        return f\"({var[side+'L']==0} and {var[side+'U']==var['maxV']})\"\n",
    "    \n",
    "    def __nsupp(self, var, L, U):\n",
    "        return '('+self.__reduce(var,'XL','XU',L,U)+' or '+ self.__reduce(var,'YL','YU',L,U)+')'\n",
    "    \n",
    "    # --------------------------- NOT SUPPORTED RULES ----------------------------\n",
    "    def NotSupported(self, res):      \n",
    "        formula, dfVars = [], self.dfVars\n",
    "        X, Y, s = self.decodeRule(res)\n",
    "       \n",
    "        formula += X.apply(lambda row: self.__nsupp(dfVars.loc[row.name],row.L,row.U), axis=1).tolist()\n",
    "        formula += Y.apply(lambda row: self.__nsupp(dfVars.loc[row.name],row.L,row.U), axis=1).tolist() \n",
    "        return f\"(not({' and '.join(formula)}))\"\n",
    "\n",
    "    # --------------------------- NOT CONFIDENT RULES ----------------------------   \n",
    "    def NotConfident(self, res):\n",
    "        formula, dfVars = [], self.dfVars\n",
    "        X, Y, s = self.decodeRule(res)\n",
    "      \n",
    "        formula += dfVars.drop(X.index).apply(lambda row: self.__notIn(row,'X'), axis=1).tolist()  \n",
    "        formula += X.apply(lambda row: self.__extend(dfVars.loc[row.name],'XL','XU',row.L,row.U), axis=1).tolist()        \n",
    "        formula += Y.apply(lambda row: self.__reduce(dfVars.loc[row.name],'YL','YU',row.L,row.U), axis=1).tolist()\n",
    "        return f\"(not({' and '.join(formula)}))\"\n",
    "\n",
    "    # ----------------------------- SUPPORTED RULES ------------------------------\n",
    "    def Confident(self, res):\n",
    "        formula, dfVars = [], self.dfVars\n",
    "        X, Y, s = self.decodeRule(res)\n",
    "        \n",
    "        formula += dfVars.drop(Y.index).apply(lambda row: self.__notIn(row,'Y'), axis=1).tolist()  \n",
    "        formula += Y.apply(lambda row: self.__extend(dfVars.loc[row.name],'YL','YU', row.L, row.U), axis=1).tolist()\n",
    "        formula += X.apply(lambda row: self.__reduce(dfVars.loc[row.name],'XL','XU', row.L, row.U), axis=1).tolist()\n",
    "        return f\"(not({' and '.join(formula)}))\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb01868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
