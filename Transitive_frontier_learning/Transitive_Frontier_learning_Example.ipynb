{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6edc0c9",
   "metadata": {},
   "source": [
    "# Air quality : Transitive frontier learnig Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda1413",
   "metadata": {},
   "source": [
    "Below is an example to implement a Transitive Frontier Learning on the Air quality dataset.\n",
    "We first show how we processed the dataset, then how to perform the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a43565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from math import log2  \n",
    "import pydotplus as ptp \n",
    "\n",
    "# helper_classes \n",
    "import import_ipynb\n",
    "import helper_general as my\n",
    "from ConstraintDefiner import ConstraintDefiner as Lark_CD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720ec58",
   "metadata": {},
   "source": [
    "## Loading + preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the correct rows and columns\n",
    "airQuality = pd.read_csv(\"./AirQualityUCI.csv\", sep=';').iloc[0:9356,1:-2] # No Date\n",
    "display(airQuality.head(3))\n",
    "\n",
    "# Replacement the \",\" with \".\" in the scientific notations \n",
    "airQuality = airQuality.astype(str).applymap(lambda val: val.replace(',','.'))\n",
    "\n",
    "# Replacement the \"(\" and \")\" with \"_\" in the columns' name to prevent grammar's errors\n",
    "airQuality.columns = [ colName.replace(\"(\",\"_\").replace(')','').replace('.','_') for colName in airQuality.columns.to_list()]\n",
    "airQuality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f8d05",
   "metadata": {},
   "source": [
    "## Mapping values, Encoder and Decoder\n",
    "Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e580d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values mapping into integer values\n",
    "encod , decod = {},{}\n",
    "for col in airQuality.columns.to_list():\n",
    "    \n",
    "    if col == \"Time\":\n",
    "        dec = airQuality[col].drop_duplicates().sort_values().reset_index(drop=True)\n",
    "    else :\n",
    "        dec = airQuality[col].astype(float).drop_duplicates().sort_values() #float-> -200 == -200.0 \n",
    "        dec = dec.iloc[1:].reset_index(drop=True) # remove the -200.0 (None) => mapping only between not None values    \n",
    "    enc = dec.reset_index().set_index(col)['index']\n",
    "    \n",
    "    encod |= {col: dict(enc)| {-200.0: -1} } # In orther to have only integer values\n",
    "    decod |= {col: dict(dec)| {-1 : -200.0}}\n",
    "#my.myDisplay([encod['CO_GT'], decod['CO_GT']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f23c4",
   "metadata": {},
   "source": [
    "Encoding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AQ = pd.DataFrame() \n",
    "for col in airQuality.columns:\n",
    "    if col == \"Time\":\n",
    "         df_AQ[col] = airQuality[col].map(lambda val: encod[col][val])\n",
    "    else:\n",
    "        df_AQ[col] = airQuality[col].map(lambda val: encod[col][float(val)]) # cast in float -> '2' == '2.0' == 2.0\n",
    "df_AQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c2f46",
   "metadata": {},
   "source": [
    "Decoding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AQ_2 = pd.DataFrame() \n",
    "for col in airQuality.columns:\n",
    "         df_AQ_2[col] = df_AQ[col].map(lambda val: decod[col][val])\n",
    "df_AQ_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878ca84",
   "metadata": {},
   "source": [
    "## Decode Air Quality Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4de862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AQ_decodeRule(decod, df_X, df_Y):\n",
    "    def colDec(col, name):\n",
    "        return col.map(lambda v: decod[name][v])  \n",
    "    \n",
    "    X = df_X.T.apply(lambda col: colDec(col, col.name)).T\n",
    "    Y = df_Y.T.apply(lambda col: colDec(col, col.name)).T\n",
    "    \n",
    "    #--------------------------\n",
    "    # Pretty rule\n",
    "    X_pretty = X.index+'['+ X.L.astype(str)+', '+X.U.astype(str)+']'\n",
    "    Y_pretty = Y.index+'['+ Y.L.astype(str)+', '+Y.U.astype(str)+']'\n",
    "    s = f\"{', '.join(X_pretty.tolist())} --> {', '.join(Y_pretty.tolist())}\"\n",
    "    \n",
    "    return X,Y,s\n",
    "\n",
    "# dX,dY,ds = AQ_decodeRule(decod, X,Y) \n",
    "# my.myDisplay([dX,dY], axis=1)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87885fc9",
   "metadata": {},
   "source": [
    "## Support and Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e165f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supp_conf(df_Coded, df_X, df_Y, tempShow=False):\n",
    "    df_temp = pd.DataFrame()\n",
    "    for col in df_X.index:\n",
    "        df_temp[col] = (df_X['L'][col] <= df_Coded[col]) & (df_Coded[col] <= df_X['U'][col])\n",
    "    \n",
    "    for col in df_Y.index:\n",
    "        df_temp[col] = (df_Y['L'][col] <= df_Coded[col]) & (df_AQ[col] <= df_Y['U'][col])\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # Calcolo freq X e XY\n",
    "    freqX = df_temp[ df_temp[df_X.index].T.sum() == len(df_X)] # freq of X \n",
    "    freqXY = freqX[freqX[df_Y.index].T.sum() == len(df_Y)]     # freq of XY\n",
    "    \n",
    "    if tempShow : my.myDisplay([df_temp,freqX,freqXY],names=['Evaluation:','X:','XY:'], axis=1)\n",
    "    return {'supp':len(freqXY)/len(df_Coded) , 'conf':0 if len(freqX)==0 else len(freqXY)/len(freqX)}\n",
    "\n",
    "# X,Y,s = c.decodeRule(res)\n",
    "# suppConf = supp_conf(df_AQ, X, Y, True)\n",
    "# suppConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e1a30",
   "metadata": {},
   "source": [
    "## Test Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b1b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after preprocessing\n",
    "df_AQ.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8a51b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select Vars to perform the analysis\n",
    "df_var = df_AQ.max().to_frame().reset_index().iloc[1:10,:]\n",
    "df_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3df3e",
   "metadata": {},
   "source": [
    "###  ConstraintDefiner Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7648b",
   "metadata": {},
   "source": [
    "This class is designed to create an interface between the user and the SAT-like core. \n",
    "It takes the variables we are interested on and their maximum value to generate constraints to guide the SAT-like search.\n",
    "\n",
    "This class try to find ranges where a rule could have some meanig. For each variable is defined a lower bond and an upper bound. The value of each variable (and its lower and upper bound) and their is represented in bits, and its evaluation is done bit by bit.\n",
    "\n",
    "The constraints implemented are: \n",
    "\n",
    "    init_constr(): that describes the structure of the rule that must be respected and the values' interval (to zero from ther maximum  values \n",
    "    NotSupported(res): Describes the constraint we want to apply in the next search if the obtained rule was not supported. \n",
    "    NotConfident(res): Describes the constraint we want to apply in the next search if the obtained rule was not confident.\n",
    "    Confident(res):    Describes the constraint we want to apply in the next search if the obtained rule was confident.\n",
    "    reject_solut(res): Describes the constraint we want to apply in the next search if we don't want the same rule again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Lark_CD(df_var['index'], df_var[0]) \n",
    "c.addConstr( c.init_constr() )  \n",
    "c.set_seed(2981050372)  # we can set a seed to reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44a8b7",
   "metadata": {},
   "source": [
    "At this point, the search is like a normal SAT-solver. We can choose to optimize the search by inserting a priority between the bits (digit) of the variables themselves. \n",
    "\n",
    "    digitPrior 'Simple': The priority is defined only between bits that represent the same variable (ex, only between the lower bound's bits or the upper bound's bits).\n",
    "    digitPrior 'Complete': The priority is defined between which represents the same range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b138850",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.set_priority(digitPrior='Complete') # none, 'Simple', 'Complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19171b2",
   "metadata": {},
   "source": [
    "To avoid long rules, we can enable the 'saturate' option which tries to assign default values to each bits.\n",
    "We decide the default values for each varialbe range is zero for the lower bound and the maximum value for the upper bound. When an attribute has the maximum interval (0-max), we decide to remove that attribute from the rule.\n",
    "\n",
    "    saturate 'all': Try to saturate all the variables that are not already assigned.\n",
    "    saturate 'effective': Try to saturate only those extremes that define the same range that doen't have values different from the default ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.set_saturate_freeVars(saturate='effective') # options:None, 'all', 'effective'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09f7f0",
   "metadata": {},
   "source": [
    "In the ConstraintDefiner, each rule is represented as a path in a binary tree. We can choose how to explore this tree (in this test, we only use the option 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.set_childrenChoice('random') #'random' or 'min_avgLenPath' or 'min_power':"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795a624",
   "metadata": {},
   "source": [
    "We can also avoid to take path that was already discarded by previous runs (always respecting the previous constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.set_resetTree(False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce299d",
   "metadata": {},
   "source": [
    "#### Start search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935ec07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decide support and confidence\n",
    "supp = 0.05\n",
    "conf = 0.8\n",
    "duration = '10h' # test durations\n",
    "\n",
    "#----------------------\n",
    "i, allBool = 0, False\n",
    "sol, state_Sol, data_Solut= [], [], []\n",
    "\n",
    "#--------------------\n",
    "duration = pd.Timedelta(duration)\n",
    "startTime = dt.datetime.now() # only for test\n",
    "\n",
    "#---------------------------\n",
    "while (dt.datetime.now() - startTime ) < duration:  \n",
    "    print(startTime - dt.datetime.now())\n",
    "    start_run = dt.datetime.now()\n",
    "    nChar = sum([len(constr) for constr in c.constr])\n",
    "    print(f\"Run:{i+1}, #char:{nChar}, Started:{start_run.strftime('%m-%d %H:%M:%S')}, \", end='')\n",
    "    print(\"\")\n",
    "    #-----------------------\n",
    "    # SAT\n",
    "    res = c.Sat_Solver(test='speed') # only for test, else:  c.Sat_Solver()\n",
    "    end_run = dt.datetime.now()\n",
    "    \n",
    "    if res is None: break    # noSoluzione\n",
    "    if len(res)==0:  \n",
    "        allBool=True    # anly true and false -> ris={}\n",
    "        break\n",
    "       \n",
    "    #-----------------------\n",
    "    # Supp + Conf\n",
    "    X,Y,s = c.decodeRule(res) # X -> antecedent, Y-> consequent, L->lower bount, U->upper bound\n",
    "    suppConf = supp_conf(df_AQ, X, Y)\n",
    "    \n",
    "    sol = {'solut':s } | suppConf\n",
    "    if suppConf['supp'] < supp:\n",
    "        c.addConstr( c.NotSupported(res) )\n",
    "        sol |= {'state':'Not supported'}\n",
    "    \n",
    "    elif suppConf['conf'] < conf:\n",
    "        c.addConstr( c.NotConfident(res) )\n",
    "        sol |= {'state':'Not confident'}\n",
    "    \n",
    "    else:\n",
    "        c.addConstr( c.Confident(res) )\n",
    "        sol |= {'state':'Confidend'}\n",
    "    \n",
    "    c.addConstr(  c.reject_solut(res) )\n",
    "    print(f\"runTime:{str(end_run - start_run)[:-7]}, TotTime:{str(end_run-startTime)[:-7]}, State:{sol['state']},\")\n",
    " \n",
    "    #-----------------------------\n",
    "    # Save sol\n",
    "    state_Sol.append(sol) \n",
    "    \n",
    "    X[['Side','idRule']], Y[['Side','idRule']] = ('X',i),('Y',i)\n",
    "    data_Solut.append([X,Y])\n",
    "    i = i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save constraints\n",
    "c.save_Constr_txt( 'AQ_contrsFile' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63382bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save state of the tested rules\n",
    "pd.DataFrame(state_Sol).to_csv('Tfl_state.csv')\n",
    "pd.DataFrame(state_Sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the rule with range attribute\n",
    "pd.concat([pd.concat(d).reset_index().set_index('idRule') for d in data_Solut]).reset_index().to_csv('Tfl_solutions.csv',index=False)\n",
    "pd.concat([pd.concat(d).reset_index().set_index('idRule') for d in data_Solut]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c57bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
